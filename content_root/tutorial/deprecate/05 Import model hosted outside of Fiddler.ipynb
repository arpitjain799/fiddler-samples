{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiddler examples have moved! [Deprecation Notice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear user thank you for using fiddler product, we appreciate your time! We have moved the examples to a new github repo located at the following link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# [New fiddler-examples repo](https://github.com/fiddler-labs/fiddler-examples)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Predict API on Model Hosted Outside of Fiddler\n",
    "Here, we will walkthrough how to use a model that is hosted external to Fiddler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiddler Client\n",
    "We begin this section as usual by establishing a connection to our\n",
    "Fiddler instance. We can establish this connection either by specifying \n",
    "our credentials directly, or by utilizing our `fiddler.ini` file. More\n",
    "information can be found in the [setup](https://github.com/fiddler-labs/fiddler-samples/blob/master/content_root/tutorial/00%20Setup.ipynb) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "\n",
    "# client = fdl.FiddlerApi(url=url, org_id=org_id, auth_token=auth_token)\n",
    "client = fdl.FiddlerApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Upload\n",
    "To upload a model, you first need to upload a sample of the data of the model’s \n",
    "inputs, targets, and additional metadata that might be useful for model analysis. \n",
    "This data sample helps us (among other things) to infer the model schema and the \n",
    "data types and values range of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# If dataset is already in Fiddler, just use it.\n",
    "if 'wine_quality' in client.list_datasets():\n",
    "    df_schema = client.get_dataset_info('wine_quality')\n",
    "    df = client.get_dataset('wine_quality')['train']\n",
    "else:\n",
    "    # Otherwise upload it.\n",
    "    df = pd.read_csv('/app/fiddler_samples/samples/datasets/winequality/train.csv')\n",
    "    df_schema = fdl.DatasetInfo.from_dataframe(df, max_inferred_cardinality=1000)\n",
    "    upload_result = client.upload_dataset(\n",
    "        dataset={'train': df}, \n",
    "        dataset_id='wine_quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Schema\n",
    "As you must have noted, in the dataset upload step we did not ask for the model’s \n",
    "features and targets, or any model specific information. That’s because we \n",
    "allow for linking multiple models to a given dataset schema. Hence we require \n",
    "an Infer model schema step which helps us know the features relevant to the \n",
    "model and the model task. Here you can specify the input features, the target \n",
    "column, decision columns and metadata columns, and also the type of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target = 'quality'\n",
    "\n",
    "feature_columns = df_schema.get_column_names()\n",
    "feature_columns.remove('row_id')\n",
    "feature_columns.remove(target)\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=df_schema,\n",
    "    target=target, \n",
    "    features=feature_columns,\n",
    "    display_name='external model',\n",
    "    description='this is an external model called from fiddler via rest API'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model Schema\n",
    "Next step, we need to save the model and any pre-processing step you had \n",
    "on the input features (for example Categorical encoder, Tokenization, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "model_dir = pathlib.Path('external_model')\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "model_dir.mkdir()\n",
    "\n",
    "with open(model_dir / 'model.yaml', 'w') as yaml_file:\n",
    "    yaml.dump({'model': model_info.to_dict()}, yaml_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write `package.py`\n",
    "A wrapper is needed between Fiddler and the model. This wrapper can be used to \n",
    "translate the inputs and outputs to fit what the model expects and what Fiddler \n",
    "is able to consume. More information can be found [here](https://docs.fiddler.ai/api-reference/package-py/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile external_model/package.py\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# make sure model generated in tutorial 02 is deployed to server\n",
    "external_model_endpoint = 'http://host.docker.internal:5100/execute/onebox/tutorial/wine_quality_model'\n",
    "\n",
    "\n",
    "class ExternalModelPackage:\n",
    "    is_classifier = False\n",
    "\n",
    "    def predict(self, input_df):\n",
    "        logging.info(f'input df: {input_df}')\n",
    "        # convert input datafrme to a format that external model accepts\n",
    "        data_array = [y.iloc[0,:].to_dict() for x , y in input_df.groupby(level=0)]\n",
    "        data = dict(data=data_array)\n",
    "        json_input = json.dumps(data)\n",
    "\n",
    "        # call external service\n",
    "        json_result = self.invoke_external_model(json_input)\n",
    "        \n",
    "        # convert response back to dataframe\n",
    "        return pd.DataFrame(json_result)\n",
    "    \n",
    "    # invoke the externa model using API\n",
    "    def invoke_external_model(self, json_input):\n",
    "        logging.info(f'input json: {json_input}')\n",
    "        headers = {'Content-type': 'application/json'}\n",
    "        result = requests.post(external_model_endpoint, \n",
    "                               headers=headers, \n",
    "                               data=json_input)\n",
    "        logging.info(f'result: {result}')\n",
    "        return result.json()['result']\n",
    "    \n",
    "def get_model():\n",
    "    return ExternalModelPackage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Model\n",
    "Now that we have all the parts that we need, we can go ahead and upload the model to the Fiddler platform. You can use the [upload_model_package](https://docs.fiddler.ai/api-reference/python-package/#upload-model-package) to upload this entire directory in one shot. We need the following for uploading a model:\n",
    "- The `path` to the directory\n",
    "- The `project_id` to which the model belongs\n",
    "- The `model_id`, which is the name you want to give the model. You can access it in Fiddler henceforth via this ID\n",
    "- The `dataset` which the model is linked to (optional)  \n",
    "\n",
    "In total, we will have a `model.yaml` and a `package.py` file within our model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'tutorial'\n",
    "model_id = 'external_model'\n",
    "client.delete_model(project_id, model_id)\n",
    "client.upload_model_package(model_dir, project_id, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "Now, let's test out our model by interfacing with the client and \n",
    "calling [run model](https://docs.fiddler.ai/api-reference/python-package/#run-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run_model(project_id, model_id, df[0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
