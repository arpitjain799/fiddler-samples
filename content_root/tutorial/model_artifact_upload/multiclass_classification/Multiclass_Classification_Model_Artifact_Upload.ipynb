{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass Classification Model Artifact Upload.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvBwWzxSw6IA"
      },
      "source": [
        "# Multiclass Classification Model Artifact Upload\n",
        "\n",
        "This notebook will go over how we can upload a multiclass classification model artifact to Fiddler and unlock the full power of explainability for your model.\n",
        "\n",
        "We will be using a model trained on a modified version of the classic [iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris).\n",
        "\n",
        "---\n",
        "\n",
        "The process is similar to registering a model without uploading an artifact. Just follow these steps:\n",
        "1. Connect to Fiddler\n",
        "2. Upload a baseline dataset\n",
        "3. Create a model package\n",
        "4. Upload the model package\n",
        "5. Test model predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4pf0LcFYe-z"
      },
      "source": [
        "## Choose your framework\n",
        "\n",
        "Fiddler supports multiple frameworks.\n",
        "\n",
        "Choose the one you want and **run the code block** to see a customized integration tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JChFchaWYBWn"
      },
      "source": [
        "#@title  { vertical-output: true, display-mode: \"form\" }\n",
        "FRAMEWORK = \"XGBoost\" #@param [\"scikit-learn\", \"TensorFlow (SavedModel)\", \"TensorFlow (HDF5)\", \"XGBoost\"]\n",
        "if FRAMEWORK == 'scikit-learn':\n",
        "    MODEL_PACKAGE_URL = 'https://github.com/fiddler-labs/fiddler-samples/blob/new-examples/content_root/tutorial/model_artifact_upload/multiclass_classification/scikit-learn/model_package.zip?raw=true'\n",
        "elif FRAMEWORK == 'TensorFlow (SavedModel)':\n",
        "    MODEL_PACKAGE_URL = 'https://github.com/fiddler-labs/fiddler-samples/blob/new-examples/content_root/tutorial/model_artifact_upload/multiclass_classification/tensorflow-savedmodel/model_package.zip?raw=true'\n",
        "elif FRAMEWORK == 'TensorFlow (HDF5)':\n",
        "    MODEL_PACKAGE_URL = 'https://github.com/fiddler-labs/fiddler-samples/blob/new-examples/content_root/tutorial/model_artifact_upload/multiclass_classification/tensorflow-hdf5/model_package.zip?raw=true'\n",
        "elif FRAMEWORK == 'XGBoost':\n",
        "    MODEL_PACKAGE_URL = 'https://github.com/fiddler-labs/fiddler-samples/blob/new-examples/content_root/tutorial/model_artifact_upload/multiclass_classification/xgboost/model_package.zip?raw=true'\n",
        "\n",
        "DATA_FILE_URL = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-samples/new-examples/content_root/tutorial/model_artifact_upload/multiclass_classification/iris_data.csv'\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Downloading model files...\")\n",
        "\n",
        "data_file_handle, _ = urlretrieve(DATA_FILE_URL, 'iris_data.csv')\n",
        "\n",
        "!rm -rf model_package;\n",
        "!mkdir model_package;\n",
        "model_package_file_handle, _ = urlretrieve(MODEL_PACKAGE_URL)\n",
        "zip_file = ZipFile(model_package_file_handle, 'r')\n",
        "zip_file.extractall('model_package')\n",
        "!rm $model_package_file_handle;\n",
        "\n",
        "print(\"Model files downloaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3UDFZ8cI61j"
      },
      "source": [
        "## 0. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwF2Pm1Uwyz2"
      },
      "source": [
        "!pip install -q fiddler-client;\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import pickle\n",
        "import pathlib\n",
        "\n",
        "import fiddler as fdl\n",
        "\n",
        "print(f\"Running client version {fdl.__version__}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewnJfHK4I869"
      },
      "source": [
        "## 1. Connect to Fiddler\n",
        "\n",
        "Connect to the Fiddler client as you normally would.\n",
        "\n",
        "For more information on how this can be done, see our [quick start guide](https://docs.fiddler.ai/pages/getting-started/quick-start/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFOcIMi3JynL"
      },
      "source": [
        "URL = #\n",
        "ORG_ID = #\n",
        "AUTH_TOKEN = #\n",
        "\n",
        "\n",
        "client = fdl.FiddlerApi(\n",
        "    url=URL,\n",
        "    org_id=ORG_ID,\n",
        "    auth_token=AUTH_TOKEN\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy1t0ATvKK4e"
      },
      "source": [
        "Next, create a new project for our regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF2iVL6SKIhR"
      },
      "source": [
        "PROJECT_ID = 'multiclass_example'\n",
        "\n",
        "client.create_project(PROJECT_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc_pAOvPKbWg"
      },
      "source": [
        "## 2. Upload a baseline dataset\n",
        "\n",
        "Now we need to upload a dataset to use as a baseline for monitoring and explainability.\n",
        "\n",
        "*For more information on how to design a baseline dataset, [click here](#).*\n",
        "\n",
        "---\n",
        "\n",
        "**We've already loaded in the CSV file for you.** Just run the following code block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDbl-DKqKdkI"
      },
      "source": [
        "PATH_TO_BASELINE_CSV = 'iris_data.csv'\n",
        "\n",
        "baseline_df = pd.read_csv(PATH_TO_BASELINE_CSV)\n",
        "baseline_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2_OMFtyLOdn"
      },
      "source": [
        "You can use this DataFrame to construct a Fiddler `DatasetInfo` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SIbu6BPLMdq"
      },
      "source": [
        "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df)\n",
        "dataset_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2PfL7aLhyP"
      },
      "source": [
        "Then, upload the dataset to Fiddler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0wxhyShLhFM"
      },
      "source": [
        "DATASET_ID = 'iris_data'\n",
        "\n",
        "client.upload_dataset(\n",
        "    project_id=PROJECT_ID,\n",
        "    dataset_id=DATASET_ID,\n",
        "    dataset={\n",
        "        'baseline': baseline_df\n",
        "    },\n",
        "    info=dataset_info\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QfGrSSKLo9P"
      },
      "source": [
        "## 3. Create a model package\n",
        "\n",
        "In order for Fiddler to use your model for explainability, you'll need to create a **model package**. This is a collection of files that helps Fiddler run your model.\n",
        "\n",
        "---\n",
        "\n",
        "Your model package should include:\n",
        "1. Your model artifact\n",
        "2. A YAML file containing specifications for your model\n",
        "3. Any other serialized objects needed to run your model (such as data transformers)\n",
        "4. A `package.py` script (more on this later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6_XVQd5lbkQ"
      },
      "source": [
        "Start by specifying a unique model ID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQNVRrPIlNMG"
      },
      "source": [
        "MODEL_ID = 'iris_classifier'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STqLfdA-V8hs"
      },
      "source": [
        "The next step is to **create a folder and store your model artifact there**.\n",
        "\n",
        "We've already loaded in a sample model artifact for you. We've stored it in the `model_package` directory.\n",
        "\n",
        "---\n",
        "\n",
        "Next, let's create a `ModelInfo` object that can be used to generate the YAML file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w5BXiJYLs-V"
      },
      "source": [
        "# Specify column types\n",
        "target = 'species'\n",
        "outputs = [\n",
        "    'probability_0',\n",
        "    'probability_1',\n",
        "    'probability_2'\n",
        "]\n",
        "features = [\n",
        "    'sepal_length',\n",
        "    'sepal_width',\n",
        "    'petal_length',\n",
        "    'petal_width'\n",
        "]\n",
        "    \n",
        "# Generate ModelInfo\n",
        "model_info = fdl.ModelInfo.from_dataset_info(\n",
        "    dataset_info=dataset_info,\n",
        "    dataset_id=DATASET_ID,\n",
        "    input_type=fdl.ModelInputType.TABULAR,\n",
        "    model_task=fdl.ModelTask.MULTICLASS_CLASSIFICATION,\n",
        "    target=target,\n",
        "    outputs=outputs,\n",
        "    features=features,\n",
        "    categorical_target_class_details=[0, 1, 2]\n",
        ")\n",
        "model_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGDKiL2YcG00"
      },
      "source": [
        "Now, let's convert the object to YAML format and store it with the artifact file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXWUlwizbcyA"
      },
      "source": [
        "with open('model_package/model.yaml', 'w') as yaml_file:\n",
        "    yaml.dump({'model': model_info.to_dict()}, yaml_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jveSOURqgmbC"
      },
      "source": [
        "The final item required for the model package is a `package.py` script. This is what tells Fiddler how to interface with a particular model.\n",
        "\n",
        "We've loaded in a sample `package.py`. Run the following code block to see what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgk3_VH5gwMr"
      },
      "source": [
        "with open('model_package/package.py', 'r') as py_file:\n",
        "    print(py_file.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HtH8sFUjiI4"
      },
      "source": [
        "***Note:*** This `package.py` script has been customized specifically for this example model. To learn more about customizing `package.py` for your own model, [click here](#)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aojEg60rkfh3"
      },
      "source": [
        "## 4. Upload the model package\n",
        "\n",
        "Almost done! The last step is to upload the model package you've created.\n",
        "\n",
        "Just run the following code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKZb0Ez-jw2L"
      },
      "source": [
        "client.upload_model_package(\n",
        "    artifact_path=pathlib.Path('model_package'),\n",
        "    project_id=PROJECT_ID,\n",
        "    model_id=MODEL_ID\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4n_Hhs_fY6G"
      },
      "source": [
        "## 5. Test model predictions\n",
        "\n",
        "We can run predictions using Fiddler's backend to **test the model and make sure everything works properly**.\n",
        "\n",
        "Just run the following code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSxqyGl3fsIO"
      },
      "source": [
        "client.run_model(\n",
        "    project_id=PROJECT_ID,\n",
        "    model_id=MODEL_ID,\n",
        "    df=baseline_df\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q37T645wk_yZ"
      },
      "source": [
        "## All done!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Questions?**  \n",
        "  \n",
        "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
        "\n",
        "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
      ]
    }
  ]
}